# --- place near other imports at top of your file ---
from urllib.parse import urljoin
from typing import List, Set
import jira_extractor   # <-- adjust to actual jira module filename if needed

# --- helper function (module-level) ---
def _dedupe_append(target_list: List[str], new_urls: List[str], seen: Set[str]):
    """
    Append unique URLs from new_urls into target_list using seen set.
    """
    for u in new_urls:
        if not u:
            continue
        if u not in seen:
            seen.add(u)
            target_list.append(u)

# --- add this method to your DownloadAttachments class ---
def _integrate_jira_nested_links(self, jira_url: str, nested_results: dict):
    """
    Fetch JIRA response (using Jira.get_ori or get_jql), extract URLs via
    save_urls_from_response/_extract_urls_from_obj, normalize and add to
    nested_results['jira'] (with dedup across the run).
    """
    # ensure nested_results buckets exist
    nested_results.setdefault('jira', [])
    nested_results.setdefault('confluence', [])
    nested_results.setdefault('external', [])

    # initialize seen set for deduplication across pages
    if not hasattr(self, '_jira_seen'):
        self._jira_seen = set()

    # instantiate or reuse Jira client
    jira_client = None
    try:
        # prefer reusing an existing jira client if you stored one on self
        jira_client = getattr(self, 'jira_client', None)
        if jira_client is None:
            # attempt a no-arg constructor; if your Jira requires args adjust below
            jira_client = jira_extractor.Jira()
            # optionally cache it for reuse
            setattr(self, 'jira_client', jira_client)
    except Exception as e:
        # if constructor fails, log and exit gracefully
        print(f"[WARN] could not instantiate Jira client: {e}")
        return

    # attempt to fetch a JIRA response object (try get_ori then get_jql)
    response_obj = None
    try:
        try:
            response_obj = jira_client.get_ori(jira_url)
        except Exception:
            response_obj = jira_client.get_jql(jira_url)
    except Exception as fetch_err:
        print(f"[WARN] Jira fetch error for {jira_url}: {fetch_err}")
        return

    # extract URLs using save_urls_from_response if available, else fallback
    extracted = []
    try:
        # save_urls_from_response often handles saving + returns list of URLs
        extracted = jira_extractor.save_urls_from_response(response_obj)
    except Exception:
        # fallback: try to convert response_obj to JSON then use low-level extractor
        try:
            payload = response_obj
            if hasattr(response_obj, 'json'):
                try:
                    payload = response_obj.json()
                except Exception:
                    # leave as-is (some methods already return dict)
                    payload = response_obj
            extracted = jira_extractor._extract_urls_from_obj(payload)
        except Exception as parse_err:
            print(f"[WARN] failed to extract urls from jira response ({jira_url}): {parse_err}")
            extracted = []

    # normalize relative URLs against the jira_url base and append deduped
    normalized = []
    for u in extracted:
        try:
            normalized.append(urljoin(jira_url, u))
        except Exception:
            normalized.append(u)

    _dedupe_append(nested_results['jira'], normalized, self._jira_seen)
