from urllib.parse import urlparse, urljoin
import requests
import os

def _normalize_filename(self, fname: str):
    """Normalize filename for comparison: strip whitespace and lower-case."""
    if not fname:
        return None
    return fname.strip().lower()

def _get_remote_filename_via_head(self, url: str, allow_fallback_get: bool = True, timeout: int = 10):
    """
    Perform a HEAD (or lightweight GET if necessary) to determine the filename the server would serve.
    Returns normalized filename (basename) or None.
    """
    if not url:
        return None
    try:
        # Use allow_redirects=True so we get final URL after redirects
        head_resp = self.session.head(urljoin(self.base_url, url), allow_redirects=True,
                                      proxies=self.proxies, verify=self.verify, timeout=timeout)
        # Some servers block HEAD - consider falling back to GET with stream=True
        if head_resp.status_code >= 400 and allow_fallback_get:
            get_resp = self.session.get(urljoin(self.base_url, url), stream=True,
                                        proxies=self.proxies, verify=self.verify, timeout=timeout)
            resp = get_resp
        else:
            resp = head_resp

        # If server provides Content-Disposition, it may include filename
        cd = resp.headers.get('content-disposition')
        if cd and 'filename=' in cd:
            # naive parse, handle common forms filename="name.ext"
            fname = cd.split('filename=')[-1].strip(' "\'')
            return self._normalize_filename(fname)

        # Otherwise use final URL path component
        final_url = resp.url if hasattr(resp, 'url') else url
        parsed = urlparse(final_url)
        fname = os.path.basename(parsed.path).split('?')[0]
        if fname:
            return self._normalize_filename(fname)
    except requests.RequestException:
        # network error or server refused HEAD; ignore and return None
        return None
    except Exception:
        return None
    return None


def download_api_then_page_with_head_dedupe(self, page_id: str, dest_folder: str):
    """
    1) First download attachments via API -> collect actual saved filenames and also remote filenames via HEAD.
    2) Then scan page links and for each candidate perform a HEAD to obtain remote filename,
       skipping those that match the API-collected filenames.
    Returns combined mapping of source -> local_path (or None if skipped/failed).
    """
    combined = {}

    # Step 1: attachments via API (authoritative)
    api_map = self.download_attachments_via_api(page_id, dest_folder) or {}
    # Create sets for quick lookup
    saved_local_filenames = set()       # basenames saved on disk (normalized)
    remote_filenames_from_api = set()   # remote filenames discovered via HEAD for API download URLs (normalized)

    # populate saved_local_filenames from api_map values
    for att_id, local_path in api_map.items():
        key = f"confluence://{page_id}/attachment/{att_id}"
        combined[key] = local_path
        if local_path:
            saved_local_filenames.add(self._normalize_filename(os.path.basename(local_path)))

    # For stronger matching, also try to get remote filename of each API download link
    # Use list_attachments_via_api to get metadata and _links.download, if available
    try:
        attachments_meta = self.list_attachments_via_api(page_id) or []
        for att in attachments_meta:
            download_rel = att.get('_links', {}).get('download')
            if not download_rel:
                continue
            download_url = urljoin(self.base_url, download_rel)
            remote_name = self._get_remote_filename_via_head(download_url)
            if remote_name:
                remote_filenames_from_api.add(remote_name)
    except Exception:
        # ignore failures here; we will at least use saved_local_filenames
        pass

    # Merge sets into one skip set
    skip_filenames_norm = set(filter(None, list(saved_local_filenames) + list(remote_filenames_from_api)))

    # Step 2: discover links in the page and skip by remote filename from HEAD
    page_soup_dict = self.confluence_content.get_page_as_html()
    if not page_soup_dict:
        print("No page HTML available to search for attachments.")
        return combined

    page_name = list(page_soup_dict.keys())[0]
    soup = page_soup_dict.get(page_name)
    if not soup:
        return combined

    links = self._find_attachment_links_in_soup(soup)
    # fallback to export_view if none found
    if not links:
        export_soup = self.confluence_content.get_page_export_view_as_html()
        if export_soup:
            export_obj = list(export_soup.values())[0] if isinstance(export_soup, dict) else export_soup
            links = self._find_attachment_links_in_soup(export_obj)

    # Now iterate candidate links
    for link in links:
        absolute_link = urljoin(self.base_url, link)
        # get remote filename via HEAD (fast)
        remote_name = self._get_remote_filename_via_head(absolute_link)
        if remote_name and remote_name in skip_filenames_norm:
            print(f"Skipping {absolute_link} because remote filename '{remote_name}' already downloaded via API.")
            combined[absolute_link] = None
            continue

        # fallback: predicted basename check (in case HEAD returned nothing)
        predicted_name = os.path.basename(urlparse(absolute_link).path).split('?')[0]
        predicted_name_norm = self._normalize_filename(predicted_name) if predicted_name else None
        if predicted_name_norm and predicted_name_norm in skip_filenames_norm:
            print(f"Skipping {absolute_link} because predicted filename '{predicted_name_norm}' already downloaded via API.")
            combined[absolute_link] = None
            continue

        # Not skipped â€” download it
        local = self.download_attachment(absolute_link, dest_folder)
        combined[absolute_link] = local
        if local:
            # Also add its basename to skip set to avoid future duplicates in same run
            skip_filenames_norm.add(self._normalize_filename(os.path.basename(local)))
            print(f"Downloaded {absolute_link} -> {local}")
        else:
            print(f"Failed to download {absolute_link}")

    return combined
