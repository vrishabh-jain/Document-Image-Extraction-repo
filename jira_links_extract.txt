import requests
import re
import json
from bs4 import BeautifulSoup


class Jira:
    def __init__(self):
        # ⚠️ Your token and URLs from the snapshot
        self.token = "ODE3ND...<redacted>...FSfEH7c"
        self.url_pre = "https://wpb-aap-utility.../jira/jql?useCache=false"
        self.url = "https://wpb-aap-utility.../jira/jql?useCache=false"

    def get_ori(self, jira_key):
        """Fetch issue details by key."""
        payload = {
            "apiPrefix": "https://wpb-jira.systems.uk.hsbc",
            "apiVersion": "2",
            "token": self.token,
            "jql": {
                "startAt": 0,
                "maxResults": 1,
                "jql": f'key="{jira_key}"'
            }
        }
        response = requests.post(self.url, json=payload, verify=False)
        return response.json()

    def get_jql(self, jql_lang):
        """Fetch issue details by custom JQL."""
        payload = {
            "apiPrefix": "https://wpb-jira.systems.uk.hsbc",
            "apiVersion": "2",
            "token": self.token,
            "jql": {
                "startAt": 0,
                "maxResults": 100,
                "jql": jql_lang
            }
        }
        response = requests.post(self.url, json=payload, verify=False)
        return response.json()


# -------- URL Extraction Helpers -------- #

URL_RE = re.compile(r'https?://[^\s"\'<>]+')

def extract_urls_from_html(html):
    """Extracts URLs from HTML using BeautifulSoup and regex fallback."""
    urls = set()
    if not html:
        return urls

    soup = BeautifulSoup(html, "html.parser")

    # <a href="...">
    for a in soup.find_all("a", href=True):
        urls.add(a["href"].strip())

    # Plain text URLs
    text = soup.get_text(separator=" ")
    urls.update(URL_RE.findall(text))

    return urls


def collect_urls_from_issue(issue_json):
    """
    Extracts URLs from JIRA issue JSON:
    - description
    - comments
    - attachments
    """
    urls = set()
    fields = issue_json.get("fields", {})

    # Description (may be plain text or HTML)
    desc = fields.get("description", "")
    urls.update(extract_urls_from_html(desc))

    # Comments
    comments = fields.get("comment", {}).get("comments", [])
    for c in comments:
        body = c.get("body", "")
        urls.update(extract_urls_from_html(body))

    # Attachments
    attachments = fields.get("attachment", [])
    for att in attachments:
        content_url = att.get("content")
        if content_url:
            urls.add(content_url)

    return list(urls)


# -------- Main Flow -------- #

def save_urls_to_json(jira, jira_urls, filename="jira_urls.json"):
    """
    Takes a list of browse URLs (e.g., https://.../browse/ABC-123),
    fetches issue data, extracts embedded URLs, and saves to JSON.
    """
    data = {}
    for url in jira_urls:
        issue_key = url.rstrip("/").split("/")[-1]  # Extract ABC-123
        print(f"Processing {issue_key} ...")

        issue_json = jira.get_ori(issue_key)
        issues = issue_json.get("issues", [])
        if not issues:
            print(f"No data found for {issue_key}")
            continue

        # First issue from response
        issue = issues[0]
        urls = collect_urls_from_issue(issue)
        data[issue_key] = urls

    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)

    print(f"✅ Extracted URLs saved to {filename}")


# -------- Example Usage -------- #

if __name__ == "__main__":
    jira = Jira()

    jira_urls = [
        "https://wpb-jira.systems.uk.hsbc/browse/ABC-123456",
        "https://wpb-jira.systems.uk.hsbc/browse/XYZ-654321",
    ]

    save_urls_to_json(jira, jira_urls)
