import requests  # already imported above
import re

# helper - place once near top of function or file
def looks_like_file_link(url, session=None, timeout=4.0):
    # quick path-extension check (fast)
    if is_file_link(url):
        return True

    # common download/attachment patterns that don't include extension
    if re.search(r'\b(download|attachment|/attachments/|/download/|/rest/api/content/.*/child/attachment)\b', url, re.I):
        return True

    # last resort: quick HEAD to inspect Content-Type / Content-Disposition
    # only do if a session is provided to avoid creating too many sessions.
    try:
        if session is None:
            return False
        resp = session.head(url, allow_redirects=True, timeout=timeout)
        ctype = (resp.headers.get("Content-Type") or "").lower()
        cdisp = resp.headers.get("Content-Disposition", "")
        if ctype and (ctype.startswith("application/") or ctype.startswith("image/") or "octet-stream" in ctype):
            return True
        if "filename=" in cdisp.lower():
            return True
    except Exception:
        # silent fallback (network issues, auth blocked, etc.)
        return False
    return False

# inside your current loop:
for a in soup.find_all("a", href=True):
    href = a["href"].strip()
    abs_url = urljoin(self.base_url, href)

    # classify files first (fast pattern check + optional HEAD via self.session)
    if looks_like_file_link(abs_url, session=getattr(self, "session", None)):
        results["links"]["files"].append(abs_url)
    elif "jira" in abs_url.lower():
        results["links"]["jira"].append(abs_url)
    elif "confluence" in abs_url.lower():
        results["links"]["confluence"].append(abs_url)
    else:
        results["links"]["external"].append(abs_url)
